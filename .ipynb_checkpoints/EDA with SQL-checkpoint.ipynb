{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://gitlab.com/ibm/skills-network/courses/placeholder101/-/raw/master/labs/module%201/images/IDSNlogo.png\"  width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n",
    "\n",
    "<h1 align=center><font size = 5>Assignment: SQL Notebook for Peer Assignment</font></h1>\n",
    "\n",
    "Estimated time needed: **60** minutes.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Using this Python notebook you will:\n",
    "\n",
    "1.  Understand the Spacex DataSet\n",
    "2.  Load the dataset  into the corresponding table in a Db2 database\n",
    "3.  Execute SQL queries to answer assignment questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the DataSet\n",
    "\n",
    "SpaceX has gained worldwide attention for a series of historic milestones.\n",
    "\n",
    "It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n",
    "SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage.\n",
    "\n",
    "Therefore if we can determine if the first stage will land, we can determine the cost of a launch.\n",
    "\n",
    "This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n",
    "\n",
    "This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the datasets\n",
    "\n",
    "This assignment requires you to load the spacex dataset.\n",
    "\n",
    "In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n",
    "\n",
    "<a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\" target=\"_blank\">Spacex DataSet</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the dataset in database table\n",
    "\n",
    "**it is highly recommended to manually load the table using the database console LOAD tool in DB2**.\n",
    "\n",
    "<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload.png\">\n",
    "\n",
    "Now open the Db2 console, open the LOAD tool, Select / Drag the .CSV file for the  dataset, Next create a New Table, and then follow the steps on-screen instructions to load the data. Name the new table as follows:\n",
    "\n",
    "**SPACEXDATASET**\n",
    "\n",
    "**Follow these steps while using old DB2 UI which is having Open Console Screen**\n",
    "\n",
    "**Note:While loading Spacex dataset, ensure that detect datatypes is disabled. Later click on the pencil icon(edit option).**\n",
    "\n",
    "1.  Change the Date Format by manually typing DD-MM-YYYY and timestamp format as DD-MM-YYYY HH\\:MM:SS.\n",
    "\n",
    "    Here you should place the cursor at Date field and manually type as DD-MM-YYYY.\n",
    "\n",
    "2.  Change the PAYLOAD_MASS\\_\\_KG\\_  datatype  to INTEGER.\n",
    "\n",
    "<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changes to be considered when having DB2 instance with the new UI having Go to UI screen**\n",
    "\n",
    "*   Refer to this insruction in this <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sign%20up%20for%20IBM%20Cloud%20-%20Create%20Db2%20service%20instance%20-%20Get%20started%20with%20the%20Db2%20console/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">link</a> for viewing  the new  Go to UI screen.\n",
    "\n",
    "*   Later click on **Data link(below SQL)**  in the Go to UI screen  and click on **Load Data** tab.\n",
    "\n",
    "*   Later browse for the downloaded spacex file.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/browsefile.png\" width=\"800\"/>\n",
    "\n",
    "*   Once done select the schema andload the file.\n",
    "\n",
    " <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload3.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, it was difficult to access IBM's Db2 due to high demand. To complete this exercise, we would make use of the postgre SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (2.8.6)\n",
      "Collecting sqlalchemy==1.3.9\n",
      "  Downloading SQLAlchemy-1.3.9.tar.gz (6.0 MB)\n",
      "Building wheels for collected packages: sqlalchemy\n",
      "  Building wheel for sqlalchemy (setup.py): started\n",
      "  Building wheel for sqlalchemy (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.9-cp38-cp38-win_amd64.whl size=1163585 sha256=1149ae662fcc53994a7715d7c9a5e769b186d373bc2221682f3b2f340f27780b\n",
      "  Stored in directory: c:\\users\\hotty\\appdata\\local\\pip\\cache\\wheels\\cb\\43\\46\\fa638f2422554332b7865d600275b24568bf60e76104a94bb4\n",
      "Successfully built sqlalchemy\n",
      "Installing collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.3.20\n",
      "    Uninstalling SQLAlchemy-1.3.20:\n",
      "      Successfully uninstalled SQLAlchemy-1.3.20\n",
      "Successfully installed sqlalchemy-1.3.9\n",
      "Collecting ibm_db_sa\n",
      "  Downloading ibm_db_sa-0.3.7.tar.gz (30 kB)\n",
      "Requirement already satisfied: sqlalchemy>=0.7.3 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ibm_db_sa) (1.3.9)\n",
      "Collecting ibm_db>=2.0.0\n",
      "  Downloading ibm_db-3.1.0.tar.gz (797 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: ibm-db-sa, ibm-db\n",
      "  Building wheel for ibm-db-sa (setup.py): started\n",
      "  Building wheel for ibm-db-sa (setup.py): finished with status 'done'\n",
      "  Created wheel for ibm-db-sa: filename=ibm_db_sa-0.3.7-py3-none-any.whl size=29309 sha256=e19052dd103f4de31d6588540d49e59d56fe6b402fc8d2e3712d81530ea7b106\n",
      "  Stored in directory: c:\\users\\hotty\\appdata\\local\\pip\\cache\\wheels\\56\\a8\\bf\\19bbcc1d370b4fdc46c95228b6db3cdb5689b4afad12da3bc4\n",
      "  Building wheel for ibm-db (PEP 517): started\n",
      "  Building wheel for ibm-db (PEP 517): finished with status 'done'\n",
      "  Created wheel for ibm-db: filename=ibm_db-3.1.0-py3-none-any.whl size=27452808 sha256=3957c56d079929a9f76b79452939d9550ad8c49b03723964eb06aabfbb6186d2\n",
      "  Stored in directory: c:\\users\\hotty\\appdata\\local\\pip\\cache\\wheels\\43\\71\\0a\\3065745bc1dc4cafbdcb09e2557082609f7689b16108b670df\n",
      "Successfully built ibm-db-sa ibm-db\n",
      "Installing collected packages: ibm-db, ibm-db-sa\n",
      "Successfully installed ibm-db-3.1.0 ibm-db-sa-0.3.7\n",
      "Requirement already satisfied: ipython-sql in c:\\users\\hotty\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython-sql) (1.3.9)\n",
      "Requirement already satisfied: ipython>=1.0 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython-sql) (7.19.0)\n",
      "Requirement already satisfied: prettytable<1 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython-sql) (0.7.2)\n",
      "Requirement already satisfied: sqlparse in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython-sql) (0.4.1)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython-sql) (1.15.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (5.0.5)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (50.3.1.post20201107)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.17.1)\n",
      "Requirement already satisfied: pygments in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (2.7.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (3.0.8)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=1.0->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hotty\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n",
      "Project libraries has been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "# install for connection to postgres database (local)\n",
    "!pip install psycopg2\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# install for connection to the database using DB2 (cloud)\n",
    "#!pip install sqlalchemy==1.3.9\n",
    "#!pip install ibm_db_sa\n",
    "#!pip install ipython-sql\n",
    "print('Project libraries has been successfully installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database using DB2\n",
    "\n",
    "Let us first load the SQL extension and establish a connection with the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DB2 magic in case of old UI service credentials.**\n",
    "\n",
    "In the next cell enter your db2 connection string. Recall you created Service Credentials for your Db2 instance before. From the **uri** field of your Db2 service credentials copy everything after db2:// (except the double quote at the end) and paste it in the cell below after ibm_db_sa://\n",
    "\n",
    "<img src =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/FinalModule_edX/images/URI.jpg\">\n",
    "\n",
    "in the following format\n",
    "\n",
    "**%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name**\n",
    "\n",
    "**DB2 magic in case of new UI service credentials.**\n",
    "\n",
    "<img src =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/servicecredentials.png\" width=600>  \n",
    "\n",
    "*   Use the following format.\n",
    "\n",
    "*   Add security=SSL at the end\n",
    "\n",
    "**%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name?security=SSL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ibm_db_dbi.InterfaceError) ibm_db_dbi::InterfaceError: connect expects a not None dsn value\n",
      "(Background on this error at: http://sqlalche.me/e/rvf5)\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%sql ibm_db_sa://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database using PostgreSQL database\n",
    "\n",
    "We tried to establish connection to the cloud database but experienced some difficulty so we decided to use the postgreSQL database. Let us load the SQL extension and establish a connection with the database using the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to database is successfully\n"
     ]
    }
   ],
   "source": [
    "# create connection to postgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host = 'localhost',\n",
    "    database = 'postgres', \n",
    "    user = 'postgres', \n",
    "    password = 'chuksoo',  \n",
    "    port = '5432')\n",
    "print('Connection to database is successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read from database\n",
    "def read(conn, read_):\n",
    "    print('Read')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(read_)\n",
    "    for row in cursor:\n",
    "        print(f'row = {row}')\n",
    "    print()\n",
    "    \n",
    "# function to create in postgre database     \n",
    "def create(conn, create_):\n",
    "    cursor = conn.cursor() # create cursor object\n",
    "    cursor.execute(create_) # execute query\n",
    "    conn.commit() # commit query to database\n",
    "    print('Table have been created successfull!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to insert in postgre database     \n",
    "def insert(conn, insert_):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(insert_)\n",
    "    conn.commit()\n",
    "    print('Records have been successfully inserted!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to update table\n",
    "def update(conn, update_):\n",
    "    print('Update')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(update_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "    \n",
    "# function to delete in postgre database\n",
    "def delete(conn, delete_):\n",
    "    print('Delete')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(delete_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "\n",
    "# close the cursor and connection to the server \n",
    "def close():\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# function to create pandas dataframe\n",
    "def create_pandas_df(sql_query, database=conn):\n",
    "    table = pd.read_sql_query(sql_query, database)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Now write and execute SQL queries to solve the assignment tasks.\n",
    "\n",
    "### Task 1\n",
    "\n",
    "##### Display the names of the unique launch sites  in the space mission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "##### Display 5 records where launch sites begin with the string 'CCA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "##### Display average payload mass carried by booster version F9 v1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "##### List the date when the first successful landing outcome in ground pad was acheived.\n",
    "\n",
    "*Hint:Use min function*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "##### List the names of the boosters which have success in drone ship and have payload mass greater than 4000 but less than 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "##### List the total number of successful and failure mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "##### List the   names of the booster_versions which have carried the maximum payload mass. Use a subquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "##### List the failed landing_outcomes in drone ship, their booster versions, and launch site names for in year 2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links\n",
    "\n",
    "*   <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20String%20Patterns%20-%20Sorting%20-%20Grouping/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01&origin=www.coursera.org\">Hands-on Lab : String Patterns, Sorting and Grouping</a>\n",
    "\n",
    "*   <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01&origin=www.coursera.org\">Hands-on Lab: Built-in functions</a>\n",
    "\n",
    "*   <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01&origin=www.coursera.org\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n",
    "\n",
    "*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n",
    "\n",
    "*   <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">Hands-on Lab: Analyzing a real World Data Set</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "\n",
    "<h4> Lakshmi Holla </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Contributors\n",
    "\n",
    "<h4> Rav Ahuja </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change log\n",
    "\n",
    "| Date       | Version | Changed by    | Change Description        |\n",
    "| ---------- | ------- | ------------- | ------------------------- |\n",
    "| 2021-10-12 | 0.4     | Lakshmi Holla | Changed markdown          |\n",
    "| 2021-08-24 | 0.3     | Lakshmi Holla | Added library update      |\n",
    "| 2021-07-09 | 0.2     | Lakshmi Holla | Changes made in magic sql |\n",
    "| 2021-05-20 | 0.1     | Lakshmi Holla | Created Initial Version   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> Â© IBM Corporation 2021. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
